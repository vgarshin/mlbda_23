{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Big Data Analysis course\n",
    "## Topic: Advanced Big Data analysis techniques\n",
    "### Part 1. Large files with Pandas and Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pandas hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from [Microsoft Malware Prediction on Kaggle](https://www.kaggle.com/competitions/microsoft-malware-prediction/overview). The goal of this competition is to predict a Windows machineâ€™s probability of getting infected by various families of malware, based on different properties of that machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we will just try to read file as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../__DATA/malware_prediction.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah $file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large file requires something else. So we are going to try some tricks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Trick 1.__ Less data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can study structure of the data with small sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...to inspect data by the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(file_path, usecols=['ProductName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(file_path, usecols=['Platform'])\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Trick 2.__ Chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None\n",
    "for chunk in tqdm(pd.read_csv(file_path, chunksize=1e5)):\n",
    "    chunk_result = chunk['Platform'].value_counts()\n",
    "    if result is None:\n",
    "        result = chunk_result\n",
    "    else:\n",
    "        result = result.add(chunk_result, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(ascending=False, inplace=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunks are good if we want to process many columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None\n",
    "for chunk in tqdm(pd.read_csv(file_path, chunksize=1e5)):\n",
    "    chunk_result = chunk['Platform'].apply(lambda x: x.replace('windows', 'WIN')) + \\\n",
    "        ' ' + chunk['ProductName']\n",
    "    if result is None:\n",
    "        result = chunk_result\n",
    "    else:\n",
    "        result = result.append(chunk_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use of Dask library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try [Dask](https://docs.dask.org/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster, progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change `n_workers` and `memory_limit` to manage performance but you should take into account your server (or cluster) resource limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    n_workers=2,\n",
    "    threads_per_worker=1,\n",
    "    memory_limit='2GB'\n",
    ")\n",
    "print(\n",
    "    'Dask dashboard available at:',\n",
    "    'https://jhas01.gsom.spbu.ru{}proxy/{}/status'.format(\n",
    "        os.environ['JUPYTERHUB_SERVICE_PREFIX'],\n",
    "        client.scheduler_info()['services']['dashboard']\n",
    "    )\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading may require defining data types, so let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'AVProductStatesIdentifier':                          'float64',\n",
    "    'AVProductsEnabled':                                  'float64',\n",
    "    'AVProductsInstalled':                                'float64',\n",
    "    'Census_FirmwareManufacturerIdentifier':              'float64',\n",
    "    'Census_FirmwareVersionIdentifier':                   'float64',\n",
    "    'Census_InternalBatteryNumberOfCharges':              'float64',\n",
    "    'Census_InternalPrimaryDisplayResolutionHorizontal':  'float64',\n",
    "    'Census_InternalPrimaryDisplayResolutionVertical':    'float64',\n",
    "    'Census_IsAlwaysOnAlwaysConnectedCapable':            'float64',\n",
    "    'Census_IsFlightsDisabled':                           'float64',\n",
    "    'Census_IsVirtualDevice':                             'float64',\n",
    "    'Census_OEMModelIdentifier':                          'float64',\n",
    "    'Census_OEMNameIdentifier':                           'float64',\n",
    "    'Census_OSInstallLanguageIdentifier':                 'float64',\n",
    "    'Census_PrimaryDiskTotalCapacity':                    'float64',\n",
    "    'Census_ProcessorClass':                              'object', \n",
    "    'Census_ProcessorCoreCount':                          'float64',\n",
    "    'Census_ProcessorManufacturerIdentifier':             'float64',\n",
    "    'Census_ProcessorModelIdentifier':                    'float64',\n",
    "    'Census_SystemVolumeTotalCapacity':                   'float64',\n",
    "    'Census_TotalPhysicalRAM':                            'float64',\n",
    "    'CityIdentifier':                                     'float64',\n",
    "    'Firewall':                                           'float64',\n",
    "    'GeoNameIdentifier':                                  'float64',\n",
    "    'IsProtected':                                        'float64',\n",
    "    'PuaMode':                                            'object', \n",
    "    'RtpStateBitfield':                                   'float64',\n",
    "    'SMode':                                              'float64',\n",
    "    'UacLuaenable':                                       'float64',\n",
    "    'Wdft_IsGamer':                                       'float64',\n",
    "    'Wdft_RegionIdentifier':                              'float64'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv(file_path, dtype=dtypes)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all columns:', ddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask uses lazy computation approach, so any processing starts only after `compute()` is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby('Platform').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.groupby('Platform').count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.groupby('Platform').Platform.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve performance by increasing number of workers and memory use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    n_workers=4,\n",
    "    threads_per_worker=1,\n",
    "    memory_limit='8GB'\n",
    ")\n",
    "print(\n",
    "    'Dask dashboard available at:',\n",
    "    'https://jhas01.gsom.spbu.ru{}proxy/{}/status'.format(\n",
    "        os.environ['JUPYTERHUB_SERVICE_PREFIX'],\n",
    "        client.scheduler_info()['services']['dashboard']\n",
    "    )\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.groupby('Platform').Platform.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby('ProductName').ProductName.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.HasDetections.unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby('HasDetections').HasDetections.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.HasDetections.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_win10 = ddf.loc[ddf.Platform == 'windows10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_win10.HasDetections.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. User's function with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.Census_OSArchitecture.unique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to Dask dataframe column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_amd(text):\n",
    "    if text == 'amd64':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "ddf = ddf.assign(\n",
    "    Census_OSArchitecture_isAMD=ddf.Census_OSArchitecture.map(\n",
    "        lambda x: is_amd(x), meta=('x', str)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby('Census_OSArchitecture_isAMD').Census_OSArchitecture_isAMD.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Dask for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further readings - [Dask for Machine Learning](https://examples.dask.org/machine-learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask_ml\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv(file_path, dtype=dtypes)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very simple model\n",
    "ml_cols = [\n",
    "    'IsBeta',\n",
    "    'AVProductsInstalled',\n",
    "    'AVProductsEnabled',\n",
    "    'HasTpm',\n",
    "    'Wdft_IsGamer',\n",
    "    'HasDetections'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier can not handle `nan` values\n",
    "ddf_ml = ddf[ml_cols].dropna()\n",
    "ddf_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'IsBeta',\n",
    "    'AVProductsInstalled',\n",
    "    'AVProductsEnabled',\n",
    "    'HasTpm',\n",
    "    'Wdft_IsGamer'\n",
    "]\n",
    "X = ddf_ml[cols]\n",
    "y = ddf_ml['HasDetections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2. Training with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('dask'):\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(preds, y_test.values.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(preds, y_test.values.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
